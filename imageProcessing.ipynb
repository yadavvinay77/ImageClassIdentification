{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define the data directory\n",
    "data_dir = 'C:/Users/yadav/OneDrive/Documents/Coding/ImageProcessing/raw-imgModified'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "images, labels = load_dataset(data_dir)\n",
    "\n",
    "# Convert the labels to categorical data\n",
    "label_names = np.unique(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define a function to display random images with class names and sizes\n",
    "def display_random_images(data_dir, label_names, num_images=10):\n",
    "    # Get a list of all image file paths in the data directory\n",
    "    image_paths = glob.glob(os.path.join(data_dir, '*', '*.jpg'))\n",
    "    # Select num_images random image file paths\n",
    "    image_paths = random.sample(image_paths, num_images)\n",
    "    # Create a figure and axes objects\n",
    "    fig, axs = plt.subplots(nrows=2, ncols=5, figsize=(12, 6))\n",
    "    # Set the title of the figure\n",
    "    fig.suptitle('Random Images from the Dataset', fontsize=16)\n",
    "    # Iterate over the randomly selected image file paths\n",
    "    for i, image_path in enumerate(image_paths):\n",
    "        # Read the image from the file path\n",
    "        image = Image.open(image_path)\n",
    "        # Get the class name from the directory name of the image\n",
    "        class_name = os.path.basename(os.path.dirname(image_path))\n",
    "        # Get the size of the image\n",
    "        size = image.size\n",
    "        # Choose the subplot to display the image and its metadata\n",
    "        row = i // 5\n",
    "        col = i % 5\n",
    "        axs[row, col].imshow(image)\n",
    "        axs[row, col].set_title(f'Class: {label_names.index(class_name)} - {class_name}\\nSize: {size}')\n",
    "        axs[row, col].axis('off')\n",
    "    # Show the figure\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call the function to display 10 random images with class names and sizes\n",
    "display_random_images(data_dir, label_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the batch size and number of epochs\n",
    "batch_size = 32\n",
    "num_epochs = 2\n",
    "\n",
    "# Define the input shape and number of classes\n",
    "input_shape = (200, 200, 3)\n",
    "num_classes = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 20946 images belonging to 10 classes.\n",
      "Found 5232 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "# Define the data generator for training and validation\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    validation_split=0.2\n",
    ")\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    data_dir,\n",
    "    target_size=input_shape[:2],\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    subset='training'\n",
    ")\n",
    "\n",
    "val_generator = train_datagen.flow_from_directory(\n",
    "    data_dir,\n",
    "    target_size=input_shape[:2],\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    subset='validation'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the InceptionResNetV2 model\n",
    "base_model = tf.keras.applications.InceptionResNetV2(\n",
    "    include_top=False,\n",
    "    weights='imagenet',\n",
    "    input_shape=input_shape\n",
    ")\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "predictions = Dense(num_classes, activation='softmax')(x)\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "# Freeze the base model layers\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Compile the model\n",
    "model.compile(\n",
    "    optimizer=Adam(),\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "417/655 [==================>...........] - ETA: 6:27 - loss: 0.3027 - accuracy: 0.9182"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    epochs=num_epochs,\n",
    "    validation_data=val_generator\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "test_loss, test_acc = model.evaluate(val_generator)\n",
    "print(f'Test loss: {test_loss:.3f*100}')\n",
    "print(f'Test accuracy: {test_acc:.3f*100}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Plot the training and validation accuracy and loss\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "plt.plot(epochs, acc, 'b', label='Training accuracy')\n",
    "plt.plot(epochs, val_acc, 'r', label='Validation accuracy')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "plt.plot(epochs, loss, 'b', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'r', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Generate predictions on the test set and plot the confusion matrix\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "labels_test = val_generator.classes\n",
    "images_test = np.concatenate([val_generator.next()[0] for i in range(val_generator.samples // batch_size)])\n",
    "\n",
    "y_pred = np.argmax(model.predict(images_test), axis=-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Plot the confusion matrix\n",
    "cm = confusion_matrix(y_true_labels, y_pred_labels)\n",
    "plt.figure(figsize=(20, 20))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=class_names, yticklabels=class_names)\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.xlabel(\"Predicted Label\")\n",
    "plt.ylabel(\"True Label\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
